{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# import numpy as np\n",
    "import rootutils\n",
    "import scanpy as sc\n",
    "import torch\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "# from torch_geometric.data import Data, Dataset\n",
    "\n",
    "rootutils.setup_root(os.getcwd(), indicator=\".project-root\", pythonpath=True)\n",
    "from torchmetrics.clustering import AdjustedRandScore, NormalizedMutualInfoScore\n",
    "\n",
    "from src.data.spatial_omics_datamodule import SpatialOmicsDataModule\n",
    "from src.models.bgrl_domain_module import BGRLDomainLitModule\n",
    "from src.utils.clustering_utils import set_leiden_resolution\n",
    "\n",
    "\n",
    "def set_seed(seed: int):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "\n",
    "set_seed(44)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datamodule = SpatialOmicsDataModule(\n",
    "    data_dir=\"../data/domain/raw\",\n",
    "    processed_dir=\"../data/domain/processed_knn_baseline/\",\n",
    "    redo_preprocess=False,\n",
    ")\n",
    "\n",
    "datamodule.prepare_data()\n",
    "datamodule.setup()\n",
    "test_dataloder = datamodule.test_dataloader()\n",
    "\n",
    "for batch in test_dataloder:\n",
    "    print(batch.sample_name[0])\n",
    "    print(batch.x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desired_sample_name = \"MERFISH_small4\"\n",
    "# desired_sample_name = \"Zhuang-ABCA-4.002\"\n",
    "batch = None\n",
    "\n",
    "for b in test_dataloder:\n",
    "    if b.sample_name[0] == desired_sample_name:\n",
    "        batch = b\n",
    "        break\n",
    "\n",
    "print(batch)\n",
    "print(batch.sample_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint_path = \"../logs/train_domain/runs/2025-03-31_15-41-12/checkpoints/epoch_011.ckpt\"\n",
    "checkpoint_path = \"../logs/augmentation/runs/2025-04-01_12-34-30/checkpoints/epoch_011.ckpt\"\n",
    "# checkpoint_path = \"../logs/abca/runs/2025-04-02_17-10-41/checkpoints/epoch_008.ckpt\"\n",
    "model = BGRLDomainLitModule.load_from_checkpoint(checkpoint_path).net.online_encoder\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    node_embeddings = model(batch.x, batch.edge_index, batch.edge_weight)\n",
    "\n",
    "# load adata object\n",
    "sample_name = batch.sample_name[0]\n",
    "file_path = os.path.join(\"../data/domain/processed_knn_baseline\", sample_name + \".h5ad\")\n",
    "adata = sc.read_h5ad(file_path)\n",
    "\n",
    "# append cell embeddings to adata object\n",
    "cell_embeddings_np = node_embeddings.cpu().numpy()\n",
    "adata.obsm[\"cell_embeddings\"] = cell_embeddings_np\n",
    "\n",
    "# get ground truth labels\n",
    "domain_name = None\n",
    "if sample_name.startswith(\"MERFISH_small\"):\n",
    "    domain_name = \"domain\"\n",
    "elif sample_name.startswith(\"STARmap\"):\n",
    "    domain_name = \"region\"\n",
    "elif sample_name.startswith(\"BaristaSeq\"):\n",
    "    domain_name = \"layer\"\n",
    "elif sample_name.startswith(\"Zhuang\"):\n",
    "    domain_name = \"parcellation_structure\"\n",
    "ground_truth_labels = adata.obs[domain_name]\n",
    "\n",
    "# determine resolution based on number of ground truth labels\n",
    "sc.pp.neighbors(adata, use_rep=\"cell_embeddings\")\n",
    "resolution = set_leiden_resolution(adata, target_num_clusters=ground_truth_labels.nunique())\n",
    "# perform leiden clustering\n",
    "sc.tl.leiden(adata, resolution=resolution)\n",
    "leiden_labels = adata.obs[\"leiden\"]\n",
    "\n",
    "# convert ground truth labels and leiden labels to PyTorch tensors\n",
    "ground_truth_labels = adata.obs[domain_name].astype(\"category\").cat.codes\n",
    "ground_truth_labels = torch.tensor(ground_truth_labels.values, dtype=torch.long)\n",
    "leiden_labels = adata.obs[\"leiden\"].astype(\"category\").cat.codes\n",
    "leiden_labels = torch.tensor(leiden_labels.values, dtype=torch.long)\n",
    "\n",
    "# calculate metrics\n",
    "test_nmi = NormalizedMutualInfoScore()\n",
    "test_ars = AdjustedRandScore()\n",
    "nmi = test_nmi(ground_truth_labels, leiden_labels)\n",
    "ari = test_ars(ground_truth_labels, leiden_labels)\n",
    "\n",
    "# log metrics for each graph\n",
    "print(f\"test/nmi: {nmi}\")\n",
    "print(f\"test/ari: {ari}\")\n",
    "\n",
    "sc.pl.embedding(adata, basis=\"spatial\", color=domain_name, size=30)\n",
    "sc.pl.embedding(adata, basis=\"spatial\", color=\"leiden\", size=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merfish4 = sc.read_h5ad(\n",
    "    \"../logS/augmentation/runs/2025-04-06_17-57-24/adata_files/MERFISH_small4.h5ad\"\n",
    ")\n",
    "merfish5 = sc.read_h5ad(\n",
    "    \"../logS/augmentation/runs/2025-04-06_17-57-24/adata_files/MERFISH_small5.h5ad\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.embedding(merfish4, basis=\"spatial\", color=\"domain\", size=30, title=\"Ground Truth\")\n",
    "sc.pl.embedding(merfish4, basis=\"spatial\", color=\"leiden\", size=30, title=\"NMI: 0.61, ARI: 0.53\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merfish5.obsm[\"spatial\"] *= -1\n",
    "merfish5.obsm[\"spatial\"][:, 0] *= -1\n",
    "\n",
    "sc.pl.embedding(merfish5, basis=\"spatial\", color=\"domain\", size=40, title=\"Ground Truth\")\n",
    "sc.pl.embedding(\n",
    "    merfish5,\n",
    "    basis=\"spatial\",\n",
    "    color=\"leiden\",\n",
    "    size=40,\n",
    "    title=\"NMI: 0.64, ARI: 0.59, HOM: 0.66, COM: 0.63\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merfish5.uns[\"leiden_colors\"] = [\n",
    "    merfish5.uns[\"leiden_colors\"][i] for i in [0, 1, 2, 4, 5, 7, 3, 6]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Flip and mirror the spatial embedding\n",
    "merfish5.obsm[\"spatial\"] *= -1\n",
    "merfish5.obsm[\"spatial\"][:, 0] *= -1\n",
    "\n",
    "# Plot the ground truth with a custom figure size\n",
    "fig, ax = plt.subplots(figsize=(6, 8))  # Adjust width and height (e.g., 6 wide, 10 tall)\n",
    "sc.pl.embedding(\n",
    "    merfish5, basis=\"spatial\", color=\"domain\", size=60, title=\"Ground Truth\", ax=ax, show=False\n",
    ")\n",
    "plt.show()\n",
    "\n",
    "# Plot the Leiden clusters with a custom figure size\n",
    "fig, ax = plt.subplots(figsize=(6, 8))  # Adjust width and height\n",
    "sc.pl.embedding(\n",
    "    merfish5,\n",
    "    basis=\"spatial\",\n",
    "    color=\"leiden\",\n",
    "    size=60,\n",
    "    title=\"NMI: 0.64, HOM: 0.66, COM: 0.63\",\n",
    "    ax=ax,\n",
    "    show=False,\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = sc.read_h5ad(\"../data/MERFISH_small5.h5ad\")\n",
    "adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Flip and mirror the spatial embedding\n",
    "adata.obsm[\"spatial\"] *= -1\n",
    "adata.obsm[\"spatial\"][:, 0] *= -1\n",
    "\n",
    "# Plot the ground truth with a custom figure size\n",
    "fig, ax = plt.subplots(figsize=(6, 8))  # Adjust width and height (e.g., 6 wide, 10 tall)\n",
    "sc.pl.embedding(\n",
    "    adata,\n",
    "    basis=\"spatial\",\n",
    "    color=\"domain_annotation\",\n",
    "    size=60,\n",
    "    title=\"Ground Truth\",\n",
    "    ax=ax,\n",
    "    show=False,\n",
    ")\n",
    "plt.show()\n",
    "\n",
    "# Plot the Leiden clusters with a custom figure size\n",
    "fig, ax = plt.subplots(figsize=(6, 8))  # Adjust width and height\n",
    "sc.pl.embedding(\n",
    "    adata,\n",
    "    basis=\"spatial\",\n",
    "    color=\"leiden\",\n",
    "    size=60,\n",
    "    title=\"NMI: 0.58, HOM: 0.57, COM: 0.60\",\n",
    "    ax=ax,\n",
    "    show=False,\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import defaultdict\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scanpy as sc\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from tqdm import tqdm\n",
    "\n",
    "graph_dir = \"../data/domain/processed_123/\"\n",
    "all_distances = []\n",
    "\n",
    "for fname in tqdm(os.listdir(graph_dir)):\n",
    "    if fname.endswith(\"graph.pt\"):\n",
    "        path = os.path.join(graph_dir, fname)\n",
    "        data: Data = torch.load(path, weights_only=False)\n",
    "\n",
    "        if hasattr(data, \"position\") and data.position is not None and data.position.size(0) > 1:\n",
    "            edge_index = data.edge_index\n",
    "            pos = data.position\n",
    "\n",
    "            src, dst = edge_index\n",
    "            dists = torch.norm(pos[src] - pos[dst], dim=1)\n",
    "\n",
    "            valid_dists = dists[dists > 0]\n",
    "            all_distances.append(valid_dists)\n",
    "\n",
    "\n",
    "all_distances = torch.cat(all_distances).cpu().numpy()\n",
    "\n",
    "plt.hist(all_distances, bins=100, density=True)\n",
    "plt.title(\"Domain123: Distribution of Intra-Graph Neighbor Distances\")\n",
    "plt.xlabel(\"Distance\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "print(\n",
    "    f\"Mean: {all_distances.mean():.4f}, Median: {np.median(all_distances):.4f}, Std: {all_distances.std():.4f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_dir = \"../data/domain/processed_123/\"\n",
    "adata_dir = graph_dir\n",
    "\n",
    "domain_features = defaultdict(list)\n",
    "stds = []\n",
    "\n",
    "for fname in os.listdir(graph_dir):\n",
    "    if fname.endswith(\"_graph.pt\"):\n",
    "        base = fname.replace(\"_graph.pt\", \"\")\n",
    "        graph = torch.load(os.path.join(graph_dir, fname), weights_only=False)\n",
    "        adata = sc.read_h5ad(os.path.join(adata_dir, base + \".h5ad\"))\n",
    "\n",
    "        graph.y = list(adata.obs[\"domain_annotation\"])\n",
    "\n",
    "        x = graph.x\n",
    "        y = graph.y\n",
    "\n",
    "        for i, domain in enumerate(y):\n",
    "            domain_features[domain].append(x[i].unsqueeze(0))\n",
    "\n",
    "for domain, feats in domain_features.items():\n",
    "    all_feats = torch.cat(feats, dim=0)\n",
    "    std = all_feats.std(dim=0)\n",
    "    stds.append(std)\n",
    "    print(f\"Domain '{domain}': mean std = {std.mean().item():.4f}\")\n",
    "print(f\"Overall mean std: {torch.mean(torch.stack(stds)).item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrain_metrics = pd.read_csv(\n",
    "    # \"../logs/phenotype_nsclc_train_baseline/runs/2025-05-12_21-45-49/csv/version_0/metrics.csv\"\n",
    "    \"../logs/phenotype_nsclc_train_baseline/runs/2025-05-13_14-14-38/csv/version_0/metrics.csv\"\n",
    ")\n",
    "pretrain_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrain_metrics = pretrain_metrics.dropna(subset=[\"train/loss_epoch\"])[\n",
    "    [\"epoch\", \"step\", \"train/loss_epoch\", \"train/lr_epoch\"]\n",
    "]\n",
    "pretrain_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style=\"whitegrid\")\n",
    "sns.lineplot(data=pretrain_metrics, x=\"epoch\", y=\"train/loss_epoch\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Pretraining Loss vs. Epoch\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style=\"whitegrid\")\n",
    "sns.lineplot(data=pretrain_metrics, x=\"epoch\", y=\"train/lr_epoch\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"LR\")\n",
    "plt.title(\"Pretraining LR vs. Epoch\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finetune_metrics = pd.read_csv(\n",
    "    # \"../logs/phenotype_nsclc_train_baseline/runs/2025-05-12_21-45-49/csv/version_1/metrics.csv\"\n",
    "    \"../logs/phenotype_nsclc_train_baseline/runs/2025-05-13_15-13-30/csv/version_1/metrics.csv\"\n",
    ")\n",
    "finetune_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finetune_metrics_train = finetune_metrics.dropna(subset=[\"train/loss_epoch\"])[\n",
    "    [\"epoch\", \"step\", \"train/loss_epoch\", \"train/lr_epoch\"]\n",
    "]\n",
    "finetune_metrics_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style=\"whitegrid\")\n",
    "sns.lineplot(data=finetune_metrics_train, x=\"epoch\", y=\"train/loss_epoch\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Finetuning Loss vs. Epoch\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style=\"whitegrid\")\n",
    "sns.lineplot(data=finetune_metrics, x=\"epoch\", y=\"train/lr_epoch\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"LR\")\n",
    "plt.title(\"Finetuning LR vs. Epoch\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finetune_metrics_val = finetune_metrics.dropna(subset=[\"val/loss\"])[\n",
    "    [\"epoch\", \"step\", \"val/loss\", \"val/f1\", \"val/accuracy\", \"val/precision\", \"val/recall\"]\n",
    "]\n",
    "finetune_metrics_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style=\"whitegrid\")\n",
    "sns.lineplot(data=finetune_metrics_val, x=\"epoch\", y=\"val/loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Finetuning Val Loss vs. Epoch\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "sns.lineplot(data=finetune_metrics_val, x=\"epoch\", y=\"val/loss\", label=\"Val Loss\")\n",
    "sns.lineplot(data=finetune_metrics_val, x=\"epoch\", y=\"val/f1\", label=\"Val F1\")\n",
    "sns.lineplot(data=finetune_metrics_val, x=\"epoch\", y=\"val/accuracy\", label=\"Val Accuracy\")\n",
    "sns.lineplot(data=finetune_metrics_val, x=\"epoch\", y=\"val/precision\", label=\"Val Precision\")\n",
    "sns.lineplot(data=finetune_metrics_val, x=\"epoch\", y=\"val/recall\", label=\"Val Recall\")\n",
    "\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Metrics\")\n",
    "plt.title(\"Finetuning Metrics vs. Epoch\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "augmentation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
