{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Graph Augmentations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## Library Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from copy import deepcopy\n",
    "from typing import Any, Dict, List, Optional, Tuple, Union\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import rootutils\n",
    "import torch\n",
    "import torch_geometric\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.utils import add_self_loops, degree, to_networkx, to_undirected\n",
    "from torch_sparse import SparseTensor\n",
    "\n",
    "rootutils.setup_root(os.getcwd(), indicator=\".project-root\", pythonpath=True)\n",
    "\n",
    "from src.utils.graph_augmentations_domain import (\n",
    "    get_graph_augmentation,\n",
    "    remove_directed_edges,\n",
    ")\n",
    "\n",
    "np.random.seed(44)\n",
    "torch.manual_seed(44)\n",
    "torch.cuda.manual_seed(44)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_graph(graph, color):\n",
    "    G = to_networkx(graph, to_undirected=False)\n",
    "\n",
    "    plt.figure(figsize=(7, 7))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    nx.draw_networkx(\n",
    "        G, pos=nx.spring_layout(G, seed=42), with_labels=True, node_color=color, cmap=\"Set2\"\n",
    "    )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_domain_graph(\n",
    "    graph_name: str,\n",
    "    num_nodes: int,\n",
    "    num_features: int,\n",
    "    num_neighbors: int,\n",
    "    num_classes: int,\n",
    "    seed: int = 44,\n",
    "    noise_scale: float = 0.05,\n",
    "    position_noise_scale: float = 0.2,\n",
    ") -> Data:\n",
    "    \"\"\"\n",
    "    Create a graph like the domain identification graphs.\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "\n",
    "    group_features = torch.rand((num_classes, num_features), dtype=torch.float)\n",
    "    group_assignments = torch.randint(0, num_classes, (num_nodes,))\n",
    "    x = group_features[group_assignments] + noise_scale * torch.randn((num_nodes, num_features))\n",
    "\n",
    "    group_positions = torch.rand((num_classes, 2), dtype=torch.float)\n",
    "    positions = group_positions[group_assignments] + position_noise_scale * torch.randn(\n",
    "        (num_nodes, 2)\n",
    "    )\n",
    "\n",
    "    nbrs = NearestNeighbors(n_neighbors=num_neighbors, algorithm=\"ball_tree\").fit(positions)\n",
    "    distances, indices = nbrs.kneighbors(positions)\n",
    "    edge_index = []\n",
    "    for i, neighbors in enumerate(indices):\n",
    "        for neighbor in neighbors:\n",
    "            if neighbor != i:\n",
    "                edge_index.append([i, neighbor])\n",
    "\n",
    "    edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
    "    edge_weight = torch.ones(edge_index.size(1), dtype=torch.float)\n",
    "\n",
    "    graph = Data(x=x, edge_index=edge_index, edge_weight=edge_weight, position=positions)\n",
    "\n",
    "    graph.edge_index = torch_geometric.utils.to_undirected(graph.edge_index)\n",
    "    graph.edge_weight = torch.ones(graph.edge_index.size(1), dtype=torch.float)\n",
    "    graph.sample_name = graph_name\n",
    "\n",
    "    assert graph.is_undirected(), \"Graph is not undirected!\"\n",
    "    assert not graph.has_self_loops(), \"Graph has self-loops!\"\n",
    "\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch_geometric.transforms import Compose\n",
    "from tqdm import tqdm\n",
    "\n",
    "from src.utils.graph_augmentations_domain import (\n",
    "    AddEdgesByFeatureSimilarity,\n",
    "    DropEdges,\n",
    "    DropFeatures,\n",
    "    DropImportance,\n",
    "    FeatureNoise,\n",
    "    ShufflePositions,\n",
    "    SpatialNoise,\n",
    ")\n",
    "\n",
    "# from copy import deepcopy\n",
    "\n",
    "\n",
    "\n",
    "# --- Configuration ---\n",
    "graph_sizes = [100, 500, 1000, 5000, 10000, 50000, 100000, 150000]\n",
    "num_features = 50\n",
    "num_neighbors = 10\n",
    "num_classes = 10\n",
    "num_runs = 3\n",
    "seed = 44\n",
    "\n",
    "augmentations = {\n",
    "    \"DropFeatures\": DropFeatures(p=0.2),\n",
    "    \"DropEdges\": DropEdges(p=0.2),\n",
    "    \"DropImportance\": DropImportance(mu=0.2, p_lambda=0.5),\n",
    "    \"SpatialNoise\": SpatialNoise(spatial_noise_std=10),\n",
    "    \"FeatureNoise\": FeatureNoise(feature_noise_std=1),\n",
    "    \"ShufflePositions\": ShufflePositions(p_shuffle=0.2),\n",
    "    \"AddEdgesByFeatureSimilarity\": AddEdgesByFeatureSimilarity(p_add=0.2, k_add=2),\n",
    "}\n",
    "\n",
    "augmentation_combos = {\n",
    "    \"DropFeatures\": [augmentations[\"DropFeatures\"]],\n",
    "    \"DropEdges\": [augmentations[\"DropEdges\"]],\n",
    "    \"SpatialNoise\": [augmentations[\"SpatialNoise\"]],\n",
    "    \"FeatureNoise\": [augmentations[\"FeatureNoise\"]],\n",
    "    \"ShufflePositions\": [augmentations[\"ShufflePositions\"]],\n",
    "    \"AddEdgesByFeatureSimilarity\": [augmentations[\"AddEdgesByFeatureSimilarity\"]],\n",
    "    \"Baseline\": [augmentations[\"DropEdges\"], augmentations[\"DropFeatures\"]],\n",
    "    \"Baseline + SpatialNoise + FeatureNoise\": [\n",
    "        augmentations[\"DropEdges\"],\n",
    "        augmentations[\"DropFeatures\"],\n",
    "        augmentations[\"SpatialNoise\"],\n",
    "        augmentations[\"FeatureNoise\"],\n",
    "    ],\n",
    "    \"DropImportance\": [augmentations[\"DropImportance\"]],\n",
    "    \"DropImportance + SpatialNoise + FeatureNoise\": [\n",
    "        augmentations[\"DropImportance\"],\n",
    "        augmentations[\"SpatialNoise\"],\n",
    "        augmentations[\"FeatureNoise\"],\n",
    "    ],\n",
    "    \"DropImportance + SpatialNoise + FeatureNoise + ShufflePositions\": [\n",
    "        augmentations[\"DropImportance\"],\n",
    "        augmentations[\"SpatialNoise\"],\n",
    "        augmentations[\"FeatureNoise\"],\n",
    "        augmentations[\"ShufflePositions\"],\n",
    "    ],\n",
    "    \"DropImportance + SpatialNoise + FeatureNoise + AddEdgesByFeatureSimilarity\": [\n",
    "        augmentations[\"DropImportance\"],\n",
    "        augmentations[\"SpatialNoise\"],\n",
    "        augmentations[\"FeatureNoise\"],\n",
    "        augmentations[\"AddEdgesByFeatureSimilarity\"],\n",
    "    ],\n",
    "}\n",
    "\n",
    "results = []\n",
    "\n",
    "# --- Benchmarking Loop ---\n",
    "for size in tqdm(graph_sizes, desc=\"Graph sizes\"):\n",
    "    graph = create_domain_graph(\n",
    "        graph_name=f\"graph_{size}\",\n",
    "        num_nodes=size,\n",
    "        num_features=num_features,\n",
    "        num_neighbors=num_neighbors,\n",
    "        num_classes=num_classes,\n",
    "        seed=seed,\n",
    "    ).to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    for name, transforms in augmentation_combos.items():\n",
    "        compose = Compose(transforms)\n",
    "\n",
    "        times = []\n",
    "        memory_usages = []\n",
    "\n",
    "        for _ in range(num_runs):\n",
    "            data = deepcopy(graph)\n",
    "\n",
    "            if torch.cuda.is_available():\n",
    "                torch.cuda.empty_cache()\n",
    "                torch.cuda.reset_peak_memory_stats()\n",
    "                torch.cuda.synchronize()\n",
    "\n",
    "            start = time.time()\n",
    "            _ = compose(data)\n",
    "            torch.cuda.synchronize() if torch.cuda.is_available() else None\n",
    "            duration = time.time() - start\n",
    "            times.append(duration)\n",
    "\n",
    "            # Memory in MB\n",
    "            if torch.cuda.is_available():\n",
    "                mem = torch.cuda.max_memory_allocated() / 1024**2\n",
    "                memory_usages.append(mem)\n",
    "            else:\n",
    "                memory_usages.append(0.0)\n",
    "\n",
    "        results.append(\n",
    "            {\n",
    "                \"augmentation\": name,\n",
    "                \"num_nodes\": size,\n",
    "                \"avg_time_s\": sum(times) / len(times),\n",
    "                \"max_memory_mb\": max(memory_usages),\n",
    "            }\n",
    "        )\n",
    "\n",
    "# --- Results ---\n",
    "df = pd.DataFrame(results)\n",
    "pivot_time = df.pivot(index=\"num_nodes\", columns=\"augmentation\", values=\"avg_time_s\")\n",
    "pivot_mem = df.pivot(index=\"num_nodes\", columns=\"augmentation\", values=\"max_memory_mb\")\n",
    "\n",
    "print(\"=== Average Runtime (s) ===\")\n",
    "print(pivot_time.round(4))\n",
    "print(\"\\n=== Max Memory Usage (MB) ===\")\n",
    "print(pivot_mem.round(2))\n",
    "\n",
    "# Optional: save results\n",
    "# df.to_csv(\"augmentation_benchmark_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_phenotype_graph(\n",
    "    graph_name: str,\n",
    "    num_nodes: int,\n",
    "    num_neighbors: int,\n",
    "    num_classes: int,\n",
    "    seed: int = 44,\n",
    "    position_noise_scale: float = 0.2,\n",
    ") -> Data:\n",
    "    \"\"\"\n",
    "    Create a graph like the phenotype prediction graphs.\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "\n",
    "    cell_types = torch.randint(0, num_classes, (num_nodes,))\n",
    "    sizes = 0.2 + 0.6 * torch.rand(num_nodes)\n",
    "    x = torch.stack([cell_types.float(), sizes], dim=1)\n",
    "\n",
    "    group_positions = torch.rand((num_classes, 2))\n",
    "    position_noise = position_noise_scale * torch.randn((num_nodes, 2))\n",
    "    positions = group_positions[cell_types] + position_noise\n",
    "\n",
    "    nbrs = NearestNeighbors(n_neighbors=num_neighbors, algorithm=\"ball_tree\").fit(positions)\n",
    "    distances, indices = nbrs.kneighbors(positions)\n",
    "\n",
    "    edge_list = []\n",
    "    edge_attrs = []\n",
    "\n",
    "    for i, (dists, neighbors) in enumerate(zip(distances, indices)):\n",
    "        for dist, j in zip(dists, neighbors):\n",
    "            if i != j:\n",
    "                edge_list.append([i, j])\n",
    "                edge_type = 0 if dist < 0.5 else 1\n",
    "                edge_attrs.append([edge_type, dist])\n",
    "\n",
    "    edge_index = torch.tensor(edge_list, dtype=torch.long).T\n",
    "    edge_attr = torch.tensor(edge_attrs, dtype=torch.float)\n",
    "\n",
    "    edge_index, edge_attr = to_undirected(edge_index, edge_attr=edge_attr)\n",
    "    edge_index, edge_attr = add_self_loops(edge_index, edge_attr=edge_attr, num_nodes=num_nodes)\n",
    "\n",
    "    graph = Data(x=x, edge_index=edge_index, edge_attr=edge_attr)\n",
    "    graph.sample_name = graph_name\n",
    "\n",
    "    assert graph.is_undirected(), \"Graph is not undirected!\"\n",
    "\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch_geometric.transforms import Compose\n",
    "from tqdm import tqdm\n",
    "\n",
    "from src.utils.graph_augmentations_phenotype import (\n",
    "    AddEdgesByCellType,\n",
    "    DropEdges,\n",
    "    DropFeatures,\n",
    "    DropImportance,\n",
    "    FeatureNoise,\n",
    "    ShufflePositions,\n",
    ")\n",
    "\n",
    "# from copy import deepcopy\n",
    "\n",
    "\n",
    "\n",
    "# --- Configuration ---\n",
    "graph_sizes = [100, 500, 1000, 5000, 10000, 50000, 100000, 150000]\n",
    "num_neighbors = 10\n",
    "num_classes = 30\n",
    "num_runs = 3\n",
    "seed = 44\n",
    "\n",
    "augmentations = {\n",
    "    \"DropFeatures\": DropFeatures(p=0.2),\n",
    "    \"DropEdges\": DropEdges(p=0.2),\n",
    "    \"DropImportance\": DropImportance(mu=0.2, p_lambda=0.5),\n",
    "    \"FeatureNoise\": FeatureNoise(feature_noise_std=1),\n",
    "    \"ShufflePositions\": ShufflePositions(p_shuffle=0.2),\n",
    "    \"AddEdgesByCellType\": AddEdgesByCellType(p_add=0.2, k_add=2),\n",
    "}\n",
    "\n",
    "augmentation_combos = {\n",
    "    \"DropFeatures\": [augmentations[\"DropFeatures\"]],\n",
    "    \"DropEdges\": [augmentations[\"DropEdges\"]],\n",
    "    \"FeatureNoise\": [augmentations[\"FeatureNoise\"]],\n",
    "    \"ShufflePositions\": [augmentations[\"ShufflePositions\"]],\n",
    "    \"AddEdgesByCellType\": [augmentations[\"AddEdgesByCellType\"]],\n",
    "    \"Baseline\": [augmentations[\"DropEdges\"], augmentations[\"DropFeatures\"]],\n",
    "    \"Baseline + FeatureNoise\": [\n",
    "        augmentations[\"DropEdges\"],\n",
    "        augmentations[\"DropFeatures\"],\n",
    "        augmentations[\"FeatureNoise\"],\n",
    "    ],\n",
    "    \"DropImportance\": [augmentations[\"DropImportance\"]],\n",
    "    \"DropImportance + FeatureNoise\": [\n",
    "        augmentations[\"DropImportance\"],\n",
    "        augmentations[\"FeatureNoise\"],\n",
    "    ],\n",
    "    \"DropImportance + FeatureNoise + ShufflePositions\": [\n",
    "        augmentations[\"DropImportance\"],\n",
    "        augmentations[\"FeatureNoise\"],\n",
    "        augmentations[\"ShufflePositions\"],\n",
    "    ],\n",
    "    \"DropImportance + FeatureNoise + AddEdgesByCellType\": [\n",
    "        augmentations[\"DropImportance\"],\n",
    "        augmentations[\"FeatureNoise\"],\n",
    "        augmentations[\"AddEdgesByCellType\"],\n",
    "    ],\n",
    "}\n",
    "\n",
    "results = []\n",
    "\n",
    "# --- Benchmarking Loop ---\n",
    "for size in tqdm(graph_sizes, desc=\"Graph sizes\"):\n",
    "    graph = create_phenotype_graph(\n",
    "        graph_name=f\"graph_{size}\",\n",
    "        num_nodes=size,\n",
    "        num_neighbors=num_neighbors,\n",
    "        num_classes=num_classes,\n",
    "        seed=seed,\n",
    "    ).to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    for name, transforms in augmentation_combos.items():\n",
    "        compose = Compose(transforms)\n",
    "\n",
    "        times = []\n",
    "        memory_usages = []\n",
    "\n",
    "        for _ in range(num_runs):\n",
    "            data = deepcopy(graph)\n",
    "\n",
    "            if torch.cuda.is_available():\n",
    "                torch.cuda.empty_cache()\n",
    "                torch.cuda.reset_peak_memory_stats()\n",
    "                torch.cuda.synchronize()\n",
    "\n",
    "            start = time.time()\n",
    "            _ = compose(data)\n",
    "            torch.cuda.synchronize() if torch.cuda.is_available() else None\n",
    "            duration = time.time() - start\n",
    "            times.append(duration)\n",
    "\n",
    "            # Memory in MB\n",
    "            if torch.cuda.is_available():\n",
    "                mem = torch.cuda.max_memory_allocated() / 1024**2\n",
    "                memory_usages.append(mem)\n",
    "            else:\n",
    "                memory_usages.append(0.0)\n",
    "\n",
    "        results.append(\n",
    "            {\n",
    "                \"augmentation\": name,\n",
    "                \"num_nodes\": size,\n",
    "                \"avg_time_s\": sum(times) / len(times),\n",
    "                \"max_memory_mb\": max(memory_usages),\n",
    "            }\n",
    "        )\n",
    "\n",
    "# --- Results ---\n",
    "df = pd.DataFrame(results)\n",
    "pivot_time = df.pivot(index=\"num_nodes\", columns=\"augmentation\", values=\"avg_time_s\")\n",
    "pivot_mem = df.pivot(index=\"num_nodes\", columns=\"augmentation\", values=\"max_memory_mb\")\n",
    "\n",
    "print(\"=== Average Runtime (s) ===\")\n",
    "print(pivot_time.round(4))\n",
    "print(\"\\n=== Max Memory Usage (MB) ===\")\n",
    "print(pivot_mem.round(2))\n",
    "\n",
    "# Optional: save results\n",
    "# df.to_csv(\"augmentation_benchmark_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "## Example Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "x = torch.tensor([[1, 5], [4, 2], [3, 6], [7, 8], [0, 3], [4, 7]], dtype=torch.float)\n",
    "edge_index = torch.tensor([[0, 3, 2, 1, 4, 4, 4, 4], [1, 5, 3, 4, 5, 3, 1, 0]], dtype=torch.long)\n",
    "edge_weight = torch.ones(edge_index.size(1), dtype=torch.float)\n",
    "sample_name = \"example_graph\"\n",
    "position = torch.tensor([[0, 0], [1, 0], [0, 1], [1, 1], [2, 0], [2, 1]], dtype=torch.float)\n",
    "\n",
    "graph = Data(\n",
    "    x=x,\n",
    "    edge_index=edge_index,\n",
    "    edge_weight=edge_weight,\n",
    "    sample_name=sample_name,\n",
    "    position=position,\n",
    ")\n",
    "graph.edge_index = torch_geometric.utils.to_undirected(graph.edge_index)\n",
    "graph.edge_weight = torch.ones(graph.edge_index.size(1), dtype=torch.float)\n",
    "\n",
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(44)\n",
    "torch.manual_seed(44)\n",
    "torch.cuda.manual_seed(44)\n",
    "\n",
    "num_nodes = 200000\n",
    "num_features = 50\n",
    "k = 10\n",
    "num_groups = 5\n",
    "noise_scale = 0.05\n",
    "position_noise_scale = 0.2\n",
    "\n",
    "group_features = torch.rand((num_groups, num_features), dtype=torch.float)\n",
    "group_assignments = torch.randint(0, num_groups, (num_nodes,))\n",
    "x = group_features[group_assignments] + noise_scale * torch.randn((num_nodes, num_features))\n",
    "\n",
    "group_positions = torch.rand((num_groups, 2), dtype=torch.float)\n",
    "positions = group_positions[group_assignments] + position_noise_scale * torch.randn((num_nodes, 2))\n",
    "\n",
    "nbrs = NearestNeighbors(n_neighbors=k, algorithm=\"ball_tree\").fit(positions)\n",
    "distances, indices = nbrs.kneighbors(positions)\n",
    "edge_index = []\n",
    "for i, neighbors in enumerate(indices):\n",
    "    for neighbor in neighbors:\n",
    "        if neighbor != i:\n",
    "            edge_index.append([i, neighbor])\n",
    "\n",
    "edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
    "edge_weight = torch.ones(edge_index.size(1), dtype=torch.float)\n",
    "\n",
    "graph = Data(x=x, edge_index=edge_index, edge_weight=edge_weight, position=positions)\n",
    "\n",
    "graph.edge_index = torch_geometric.utils.to_undirected(graph.edge_index)\n",
    "graph.edge_weight = torch.ones(graph.edge_index.size(1), dtype=torch.float)\n",
    "graph.sample_name = \"example_graph\"\n",
    "\n",
    "graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "## Graph Augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform1 = get_graph_augmentation(\n",
    "    augmentation_mode=\"advanced\",\n",
    "    augmentation_list=[\"DropImportance\", \"SpatialNoise\", \"AddEdgesByFeatureSimilarity\"],\n",
    "    drop_edge_p=0.3,\n",
    "    drop_feat_p=0.3,\n",
    "    mu=0.2,\n",
    "    p_lambda=0.5,\n",
    "    p_rewire=0.3,\n",
    "    p_shuffle=0.1,\n",
    "    spatial_noise_std=0.01,\n",
    "    feature_noise_std=0.01,\n",
    "    p_add=0.2,\n",
    "    k_add=2,\n",
    ")\n",
    "transform1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform2 = get_graph_augmentation(\n",
    "    augmentation_mode=\"advanced\",\n",
    "    augmentation_list=[\"DropImportance\"],\n",
    "    drop_edge_p=0.3,\n",
    "    drop_feat_p=0.3,\n",
    "    mu=0.2,\n",
    "    p_lambda=0.5,\n",
    "    p_rewire=0.2,\n",
    "    p_shuffle=0.2,\n",
    "    spatial_noise_std=0.01,\n",
    "    feature_noise_std=0.01,\n",
    "    p_add=0.1,\n",
    "    k_add=3,\n",
    ")\n",
    "transform2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "aug1 = transform1(graph)\n",
    "aug1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "aug2 = transform2(graph)\n",
    "aug2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "aug1.is_undirected()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "aug2.is_undirected()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    transform1 = get_graph_augmentation(\n",
    "        augmentation_mode=\"advanced\",\n",
    "        augmentation_list=[\"DropImportance\", \"SpatialNoise\"],\n",
    "        drop_edge_p=0.3,\n",
    "        drop_feat_p=0.3,\n",
    "        mu=0.3,\n",
    "        p_lambda=0.3,\n",
    "        p_rewire=0.5,\n",
    "        p_shuffle=0.1,\n",
    "        spatial_noise_std=0.01,\n",
    "        feature_noise_std=0.01,\n",
    "        p_add=0.1,\n",
    "        k_add=3,\n",
    "    )\n",
    "    data = transform1(graph)\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_graph(aug1, color=\"red\")\n",
    "visualize_graph(aug2, color=\"green\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "## Proprotional Resampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "alpha = 0.0  # weighting factor: 0 = only spatial, 1 = only expression\n",
    "n_clusters = 5\n",
    "new_distribution = None\n",
    "\n",
    "x = data.x.cpu().numpy()\n",
    "pos = data.position.cpu().numpy()\n",
    "\n",
    "x_scaled = StandardScaler().fit_transform(x)\n",
    "pos_scaled = StandardScaler().fit_transform(pos)\n",
    "combined_features = np.concatenate([alpha * x_scaled, (1 - alpha) * pos_scaled], axis=1)\n",
    "\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=44).fit(combined_features)\n",
    "cluster_labels = kmeans.labels_\n",
    "cluster_to_indices = {i: np.where(cluster_labels == i)[0] for i in range(n_clusters)}\n",
    "\n",
    "if new_distribution is None:\n",
    "    new_distribution = {i: 1/n_clusters for i in range(n_clusters)}\n",
    "\n",
    "new_node_indices = []\n",
    "for cluster_id, proportion in new_distribution.items():\n",
    "    n = int(proportion * data.num_nodes)\n",
    "    candidates = cluster_to_indices[cluster_id]\n",
    "    chosen = np.random.choice(candidates, n, replace=len(candidates) < n)\n",
    "    new_node_indices.extend(chosen)\n",
    "\n",
    "new_node_indices = torch.tensor(new_node_indices, dtype=torch.long)\n",
    "\n",
    "from torch_geometric.utils import subgraph\n",
    "new_edge_index, new_edge_weight = subgraph(\n",
    "    subset=new_node_indices, edge_index=data.edge_index, edge_attr=data.edge_weight, relabel_nodes=True\n",
    ")\n",
    "data = Data(\n",
    "    x=data.x[new_node_indices],\n",
    "    edge_index=new_edge_index,\n",
    "    edge_weight=new_edge_weight,\n",
    "    position=data.position[new_node_indices],\n",
    "    sample_name=data.sample_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.graph_augmentations_phenotype import get_graph_augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = torch.load(\"../data/phenotype/nsclc/processed/175A_100.0.gpt\", weights_only=False)\n",
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = get_graph_augmentation(\n",
    "    augmentation_mode=\"advanced\",\n",
    "    augmentation_list=[\"ShufflePositions\"],\n",
    "    drop_edge_p=0.3,\n",
    "    drop_feat_p=0.2,\n",
    "    mu=0.2,\n",
    "    p_lambda=0.5,\n",
    "    p_rewire=0.5,\n",
    "    feature_noise_std=0.01,\n",
    "    p_add=0.1,\n",
    "    k_add=3,\n",
    "    p_shuffle=0.1,\n",
    ")\n",
    "transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = transform(graph)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "(graph.edge_index != data.edge_index).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "augmentation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
