# @package _global_

# to execute this experiment run:
# python src/train_domain.py -m hparams_search=domain7_augmentation experiment=domain7_hparam_augmentation

defaults:
  - override /data: spatial_omics
  - override /model: bgrl_domain
  - override /trainer: gpu

# all parameters below will be merged with parameters from default configurations set above
# this allows you to overwrite only specified parameters

task_name: "domain7_hparam_augmentation"
tags: ["domain7", "hparam", "augmentation"]
validate: True

data:
  data_dir: ${paths.data_dir}domain/raw_7/
  processed_dir: ${paths.data_dir}domain/processed_7/
  batch_size: 8
  num_workers: 4
  pin_memory: False
  min_cells: 2
  min_genes: 10
  augmentation_mode: "baseline"
  lambda_param: 0.1
  sigma_param: 0.1
  n_pca_components: 50
  graph_method: "knn"
  n_neighbors: 10
  redo_preprocess: False

model:
  net:
    encoder:
      input_size: 50
      hidden_size: 32
      output_size: 16
      dropout: 0.5
    projector:
      input_size: ${model.net.encoder.output_size}
      output_size: ${model.net.encoder.output_size}
      hidden_size: 32

  optimizer:
    _partial_: true
    lr: 0.005
    weight_decay: 1e-4

  scheduler:
    _partial_: true
    T_max: 25974
    eta_min: 1e-7

  compile: false
  augmentation_mode: "advanced"
  augmentation_list1: ["DropImportance", "SpatialNoise"]
  augmentation_list2: ["DropImportance", "FeatureNoise"]
  mm: 0.99
  warmup_steps: 100
  total_steps: 25974
  spatial_regularization_strength: 0.0
  node_subset_sz: 5000
  drop_edge_p1: 0.
  drop_edge_p2: 0.
  drop_feat_p1: 0.
  drop_feat_p2: 0.
  mu: 0.1
  p_lambda: 0.2
  p_rewire: 0.
  p_shuffle: 0.
  spatial_noise_std: 0.02
  feature_noise_std: 0.18
  p_add: 0.1
  k_add: 3
  processed_dir: ${paths.data_dir}domain/processed_7/

trainer:
  min_epochs: 1
  max_epochs: 999
  log_every_n_steps: 4
  check_val_every_n_epoch: 9999
  precision: 16
  accumulate_grad_batches: 4
