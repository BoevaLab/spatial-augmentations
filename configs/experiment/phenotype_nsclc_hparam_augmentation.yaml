# @package _global_

# to execute this experiment run:
# python src/train_phenotype.py -m hparams_search=phenotype_nsclc_augmentation experiment=phenotype_nsclc_hparam_augmentation

defaults:
  - override /data@finetune.data: cellular_graph
  - override /model@finetune.model: gnn_pred_phenotype
  - override /trainer@finetune.trainer: gpu

  - override /data@pretrain.data: cellular_graph
  - override /model@pretrain.model: bgrl_phenotype
  - override /trainer@pretrain.trainer: gpu

# all parameters below will be merged with parameters from default configurations set above
# this allows you to overwrite only specified parameters

task_name: "phenotype_nsclc_hparam_augmentation"
tags: ["phenotype", "nsclc", "hparam", "augmentation"]

pretrain:
  data:
    mode: "pretraining"

  model:
    augmentation_mode: "advanced"
    augmentation_list1: ["DropImportance", "AddEdgesByCellType"]
    augmentation_list2: ["DropImportance", "AddEdgesByCellType", "FeatureNoise"]

  trainer:
    min_epochs: 1
    max_epochs: 50000
    log_every_n_steps: 10
    check_val_every_n_epoch: 99999
    limit_train_batches: 1

finetune:
  data:
    mode: "finetuning"
    redo_preprocess: False

  trainer:
    min_epochs: 1
    max_epochs: 50000
    log_every_n_steps: 10
    check_val_every_n_epoch: 1000
    limit_train_batches: 1
