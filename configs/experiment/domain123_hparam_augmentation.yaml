# @package _global_

# to execute this experiment run:
# python train.py experiment=domain123_hparam_augmentation

defaults:
  - override /data: spatial_omics
  - override /model: bgrl_domain
  - override /trainer: gpu

# all parameters below will be merged with parameters from default configurations set above
# this allows you to overwrite only specified parameters

task_name: "domain123_hparam_augmentation"
tags: ["domain123", "hparam", "augmentation"]
validate: True

data:
  data_dir: ${paths.data_dir}domain/raw_123/
  processed_dir: ${paths.data_dir}domain/processed_123/
  batch_size: 4
  num_workers: 0
  pin_memory: False
  min_cells: 2
  min_genes: 10
  augmentation_mode: "baseline"
  lambda_param: 0.1
  sigma_param: 0.1
  n_pca_components: 50
  graph_method: "knn"
  n_neighbors: 10
  redo_preprocess: False

model:
  net:
    encoder:
      input_size: 50
      hidden_size: 32
      output_size: 16
      dropout: 0.5
    projector:
      input_size: ${model.net.encoder.output_size}
      output_size: ${model.net.encoder.output_size}
      hidden_size: 64

  optimizer:
    _partial_: true
    lr: 0.0002
    weight_decay: 0.08

  scheduler:
    _partial_: true
    T_max: 2997
    eta_min: 1e-7

  compile: false # compile model for faster training with pytorch 2.0
  augmentation_mode: "advanced" # augmetation mode, either baseline or advanced
  augmentation_list1: [
      "DropImportance",
      "SpatialNoise",
      "AddEdgesByFeatureSimilarity",
    ] # list of augmentations to apply for first view
  augmentation_list2: [
      "DropImportance",
      "FeatureNoise",
      "AddEdgesByFeatureSimilarity",
    ] # list of augmentations to apply for second view
  mm: 0.97 # momentum for moving average of target encoder
  warmup_steps: 200 # number of warmup steps
  total_steps: 2997 # total number of training steps
  spatial_regularization_strength: 0.0 # hyperparameter for the spatial regularization
  node_subset_sz: 5000 # number of nodes to sample for accelerated spatial regularization
  drop_edge_p1: 0. # drop edge probability for first augmentation
  drop_edge_p2: 0. # drop edge probability for second augmentation
  drop_feat_p1: 0. # drop feature probability for first augmentation
  drop_feat_p2: 0. # drop feature probability for second augmentation
  mu: 0.1 # hyperparameter for the graph augmentation
  p_lambda: 0.2 # hyperparameter for the graph augmentation
  p_rewire: 0. # hyperparameter for the graph augmentation
  p_shuffle: 0. # hyperparameter for the graph augmentation
  spatial_noise_std: 22.5 # standard deviation of the spatial noise
  feature_noise_std: 0.03 # standard deviation of the feature noise
  p_add: 0.1 # hyperparameter for the graph augmentation
  k_add: 3 # hyperparameter for the graph augmentation
  processed_dir: ${paths.data_dir}domain/processed_123/ # directory for processed data

trainer:
  min_epochs: 1 # prevents early stopping
  max_epochs: 999
  log_every_n_steps: 2
  check_val_every_n_epoch: 9999
