_target_: src.models.bgrl_domain_module.BGRLDomainLitModule

net:
  _target_: src.models.components.bgrl.BGRL
  encoder:
    _target_: src.models.components.two_layer_gcn.TwoLayerGCN
    input_size: 50
    hidden_size: 32
    output_size: 16
    dropout: 0.5
  projector:
    _target_: src.models.components.bgrl_projector.BGRLProjector
    input_size: ${model.net.encoder.output_size}
    output_size: ${model.net.encoder.output_size}
    hidden_size: 32

optimizer:
  _target_: torch.optim.Adam
  _partial_: true
  lr: 0.005
  weight_decay: 1e-4

scheduler:
  _target_: torch.optim.lr_scheduler.CosineAnnealingLR
  _partial_: true
  T_max: 2000
  eta_min: 1e-7

compile: false # compile model for faster training with pytorch 2.0
augmentation_mode: "baseline" # augmetation mode, either baseline or advanced
augmentation_list1: [] # list of augmentations to apply for the first view (only necessary for advanced mode)
augmentation_list2: [] # list of augmentations to apply for the second view (only necessary for advanced mode)
mm: 0.99 # momentum for moving average of target encoder
warmup_steps: 100 # number of warmup steps
total_steps: 2000 # total number of training steps
spatial_regularization_strength: 0.0 # hyperparameter for the spatial regularization
node_subset_sz: 5000 # number of nodes to sample for accelerated spatial regularization
drop_edge_p1: 0.3 # drop edge probability for first augmentation
drop_edge_p2: 0.3 # drop edge probability for second augmentation
drop_feat_p1: 0.3 # drop feature probability for first augmentation
drop_feat_p2: 0.3 # drop feature probability for second augmentation
mu: 0.3 # hyperparameter for the graph augmentation
p_lambda: 0.3 # hyperparameter for the graph augmentation
p_rewire: 0.1 # hyperparameter for the graph augmentation
p_shuffle: 0.1 # hyperparameter for the graph augmentation
spatial_noise_std: 0.01 # standard deviation of the spatial noise augmentation
processed_dir: ${paths.data_dir}domain/processed/ # directory for processed data
seed: ${seed} # random seed
