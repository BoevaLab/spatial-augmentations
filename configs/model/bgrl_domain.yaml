_target_: src.models.bgrl_module.BGRLLitModule

net:
  _target_: src.models.components.bgrl.BGRL
  encoder:
    _target_: src.models.components.two_layer_gcn.TwoLayerGCN
    input_size: 50
    hidden_size: 32
    output_size: 16
    dropout: 0.5
  projector:
    _target_: src.models.components.bgrl_projector.BGRLProjector
    input_size: 16
    output_size: 16
    hidden_size: 32

optimizer:
  _target_: torch.optim.Adam
  _partial_: true
  lr: 0.005
  weight_decay: 1e-4

scheduler:
  _target_: torch.optim.lr_scheduler.CosineAnnealingLR
  _partial_: true
  T_max: 2000
  eta_min: 1e-5

compile: false # compile model for faster training with pytorch 2.0
augmentation_mode: "baseline" # augmetation mode, either baseline or advanced
mm: 0.99 # momentum for moving average of target encoder
warmup_steps: 100 # number of warmup steps
total_steps: 2000 # total number of training steps
drop_edge_p1: 0.3 # drop edge probability for first augmentation
drop_edge_p2: 0.3 # drop edge probability for second augmentation
drop_feat_p1: 0.3 # drop feature probability for first augmentation
drop_feat_p2: 0.3 # drop feature probability for second augmentation
mu: 0.5 # hyperparameter for the graph augmentation
spatial_regularization_strength: 0.0 # hyperparameter for the spatial regularization
node_subset_sz: 5000 # number of nodes to sample for accelerated spatial regularization
p_lambda: 0.7 # hyperparameter for the graph augmentation
processed_dir: ${paths.data_dir}domain/processed/ # directory for processed data
